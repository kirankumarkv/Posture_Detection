{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfb4af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from collections import deque, Counter\n",
    "import joblib\n",
    "from IPython.display import display, clear_output, HTML\n",
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7887b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9943300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landmark configuration\n",
    "LANDMARK_INDICES = [0, 2, 5, 7, 8, 9, 10, 11, 12]  # Key landmarks for posture\n",
    "POSE_CLASSES = ['leaning_backward', 'leaning_forward', 'leaning_left', 'leaning_right', 'upright']\n",
    "POSE_COLORS = {\n",
    "    'leaning_backward': (0, 0, 255),      # Red\n",
    "    'leaning_forward': (0, 255, 0),       # Green\n",
    "    'leaning_left': (255, 0, 0),          # Blue\n",
    "    'leaning_right': (0, 255, 255),       # Yellow\n",
    "    'upright': (255, 0, 255)              # Magenta\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3605092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EnhancedPostureDetector:\n",
    "    def __init__(self, model_path, scaler_path, label_encoder_path):\n",
    "        \"\"\"Initialize with trained models matching the training architecture\"\"\"\n",
    "        try:\n",
    "            # Load preprocessing\n",
    "            self.scaler = joblib.load(scaler_path)\n",
    "            self.label_encoder = joblib.load(label_encoder_path)\n",
    "            \n",
    "            # Rebuild exact model architecture from training code\n",
    "            self.model = self._build_identical_model()\n",
    "            \n",
    "            # Load weights\n",
    "            self.model.load_weights(model_path)\n",
    "            \n",
    "            # Calibration and smoothing\n",
    "            self.calibrated_upright = None\n",
    "            self.calibration_samples = deque(maxlen=30)\n",
    "            self.prediction_history = deque(maxlen=5)\n",
    "            \n",
    "            print(\"‚úÖ Model loaded with identical architecture to training\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Model initialization failed: {str(e)}\")\n",
    "    \n",
    "    def _build_identical_model(self):\n",
    "        \"\"\"Rebuild the EXACT architecture from training code\"\"\"\n",
    "        input_layer = tf.keras.layers.Input(shape=(9, 4), name='input_layer')\n",
    "        \n",
    "        # Conv Blocks (exactly as in training)\n",
    "        x = tf.keras.layers.Conv1D(128, 2, activation='relu')(input_layer)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Conv1D(128, 2, activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.MaxPooling1D(2)(x)\n",
    "        x = tf.keras.layers.Dropout(0.4)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv1D(64, 2, activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Conv1D(64, 2, activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        \n",
    "        # LSTM Blocks (exactly as in training)\n",
    "        x = tf.keras.layers.LSTM(100, return_sequences=True, \n",
    "                                dropout=0.4, recurrent_dropout=0.4)(x)\n",
    "        x = tf.keras.layers.LSTM(80, return_sequences=True,\n",
    "                               dropout=0.4, recurrent_dropout=0.4)(x)\n",
    "        x = tf.keras.layers.LSTM(50, dropout=0.4, recurrent_dropout=0.4)(x)\n",
    "        \n",
    "        # Dense Layers (exactly as in training)\n",
    "        x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(0.4)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        \n",
    "        output_layer = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
    "        \n",
    "        model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "        model.compile(optimizer='adam',\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def extract_landmarks(self, pose_landmarks):\n",
    "        \"\"\"Extract and normalize key landmarks (matches training preprocessing)\"\"\"\n",
    "        if not pose_landmarks:\n",
    "            return None\n",
    "            \n",
    "        landmarks = []\n",
    "        valid_points = 0\n",
    "        \n",
    "        for idx in LANDMARK_INDICES:\n",
    "            if idx < len(pose_landmarks.landmark):\n",
    "                lm = pose_landmarks.landmark[idx]\n",
    "                if lm.visibility > 0.3:  # Same threshold as training\n",
    "                    valid_points += 1\n",
    "                landmarks.append([lm.x, lm.y, lm.z, lm.visibility])\n",
    "            else:\n",
    "                landmarks.append([0.0, 0.0, 0.0, 0.0])\n",
    "        \n",
    "        return np.array(landmarks, dtype=np.float32) if valid_points >= 5 else None\n",
    "    \n",
    "    def preprocess_input(self, landmarks):\n",
    "        \"\"\"Identical preprocessing to training pipeline\"\"\"\n",
    "        if landmarks is None:\n",
    "            return None\n",
    "            \n",
    "        # Flatten and scale exactly like training\n",
    "        flattened = landmarks.flatten()\n",
    "        scaled = self.scaler.transform([flattened])\n",
    "        return scaled.reshape(1, 9, 4)\n",
    "    \n",
    "    def predict_posture(self, landmarks):\n",
    "        \"\"\"Make prediction with identical processing as training\"\"\"\n",
    "        processed = self.preprocess_input(landmarks)\n",
    "        if processed is None:\n",
    "            return \"No Pose\", 0.0\n",
    "            \n",
    "        # Predict with identical model architecture\n",
    "        predictions = self.model.predict(processed, verbose=0)\n",
    "        class_idx = np.argmax(predictions[0])\n",
    "        confidence = np.max(predictions[0])\n",
    "        posture = self.label_encoder.inverse_transform([class_idx])[0]\n",
    "        \n",
    "        # Temporal smoothing\n",
    "        self.prediction_history.append(posture)\n",
    "        if len(self.prediction_history) >= 3:\n",
    "            posture = Counter(self.prediction_history).most_common(1)[0][0]\n",
    "        \n",
    "        return posture, confidence\n",
    "\n",
    "    def save_calibration(self):\n",
    "        if len(self.calibration_samples) == 0:\n",
    "            return\n",
    "        self.calibrated_upright = np.mean(np.array(self.calibration_samples), axis=0)\n",
    "        self.calibration_samples.clear()\n",
    "    \n",
    "    def calibrate_sample(self, landmarks):\n",
    "        if landmarks is not None:\n",
    "            self.calibration_samples.append(landmarks)\n",
    "    \n",
    "    def delta_from_calibrated(self, landmarks):\n",
    "        if self.calibrated_upright is None or landmarks is None:\n",
    "            return landmarks\n",
    "        return landmarks - self.calibrated_upright\n",
    "\n",
    "\n",
    "class PostureDetectionApp:\n",
    "    \"\"\"Standalone posture detection app with matplotlib display\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path='enhanced_cnn_lstm_model.h5',\n",
    "                 scaler_path='enhanced_cnn_lstm_scaler.pkl',\n",
    "                 label_encoder_path='enhanced_cnn_lstm_label_encoder.pkl'):\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(\"POSTURE DETECTION SYSTEM\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\nInitializing...\")\n",
    "        \n",
    "        try:\n",
    "            self.detector = EnhancedPostureDetector(\n",
    "                model_path=model_path,\n",
    "                scaler_path=scaler_path,\n",
    "                label_encoder_path=label_encoder_path\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load model: {e}\")\n",
    "            print(\"\\nPlease check that these files exist:\")\n",
    "            print(f\"  - {model_path}\")\n",
    "            print(f\"  - {scaler_path}\")\n",
    "            print(f\"  - {label_encoder_path}\")\n",
    "            raise\n",
    "        \n",
    "        self.pose = mp_pose.Pose(\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5,\n",
    "            model_complexity=1\n",
    "        )\n",
    "        \n",
    "        self.cap = None\n",
    "        self.is_running = False\n",
    "        self.is_calibrating = False\n",
    "        self.calibrated = False\n",
    "        \n",
    "        # Create matplotlib figure for results display\n",
    "        plt.ion()  # Interactive mode\n",
    "        self.fig, (self.ax_main, self.ax_status) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        self.fig.canvas.manager.set_window_title('Posture Detection Results')\n",
    "        \n",
    "        self.setup_display()\n",
    "        \n",
    "        print(\"‚úÖ App initialized successfully!\")\n",
    "    \n",
    "    def setup_display(self):\n",
    "        \"\"\"Setup the matplotlib display\"\"\"\n",
    "        # Main video display\n",
    "        self.ax_main.set_title('Live Feed with Pose Detection', fontsize=14, fontweight='bold')\n",
    "        self.ax_main.axis('off')\n",
    "        \n",
    "        # Status panel\n",
    "        self.ax_status.set_xlim(0, 10)\n",
    "        self.ax_status.set_ylim(0, 10)\n",
    "        self.ax_status.axis('off')\n",
    "        self.ax_status.set_title('Status & Controls', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    def update_status_panel(self, posture=None, confidence=0.0, fps=0):\n",
    "        \"\"\"Update the status panel with current information\"\"\"\n",
    "        self.ax_status.clear()\n",
    "        self.ax_status.set_xlim(0, 10)\n",
    "        self.ax_status.set_ylim(0, 10)\n",
    "        self.ax_status.axis('off')\n",
    "        \n",
    "        y_pos = 9.5\n",
    "        \n",
    "        # Title\n",
    "        self.ax_status.text(5, y_pos, 'POSTURE STATUS', ha='center', fontsize=16, \n",
    "                           fontweight='bold', color='#2c3e50')\n",
    "        y_pos -= 1.2\n",
    "        \n",
    "        # Calibration status\n",
    "        cal_color = '#27ae60' if self.calibrated else '#e67e22'\n",
    "        cal_text = '‚úì CALIBRATED' if self.calibrated else '‚ö† NOT CALIBRATED'\n",
    "        self.ax_status.text(5, y_pos, cal_text, ha='center', fontsize=12, \n",
    "                           fontweight='bold', color=cal_color)\n",
    "        y_pos -= 1\n",
    "        \n",
    "        # Current posture\n",
    "        if posture and self.calibrated:\n",
    "            posture_display = posture.replace('_', ' ').upper()\n",
    "            color_bgr = POSE_COLORS.get(posture, (128, 128, 128))\n",
    "            color_rgb = (color_bgr[2]/255, color_bgr[1]/255, color_bgr[0]/255)\n",
    "            \n",
    "            # Draw colored box behind posture\n",
    "            rect = patches.Rectangle((1, y_pos-0.5), 8, 1.2, \n",
    "                                    linewidth=2, edgecolor=color_rgb, \n",
    "                                    facecolor=(*color_rgb, 0.2))\n",
    "            self.ax_status.add_patch(rect)\n",
    "            \n",
    "            self.ax_status.text(5, y_pos, posture_display, ha='center', fontsize=14, \n",
    "                               fontweight='bold', color=color_rgb)\n",
    "            y_pos -= 1.5\n",
    "            \n",
    "            # Confidence bar\n",
    "            self.ax_status.text(2, y_pos, 'Confidence:', ha='left', fontsize=10)\n",
    "            \n",
    "            # Background bar\n",
    "            rect_bg = patches.Rectangle((2, y_pos-0.4), 6, 0.3, \n",
    "                                       linewidth=1, edgecolor='gray', facecolor='lightgray')\n",
    "            self.ax_status.add_patch(rect_bg)\n",
    "            \n",
    "            # Confidence bar\n",
    "            bar_width = 6 * confidence\n",
    "            rect_conf = patches.Rectangle((2, y_pos-0.4), bar_width, 0.3, \n",
    "                                         linewidth=0, facecolor=color_rgb)\n",
    "            self.ax_status.add_patch(rect_conf)\n",
    "            \n",
    "            self.ax_status.text(8.2, y_pos, f'{confidence:.0%}', ha='left', fontsize=10, \n",
    "                               fontweight='bold')\n",
    "            y_pos -= 1.2\n",
    "        \n",
    "        # Separator line\n",
    "        self.ax_status.plot([1, 9], [y_pos, y_pos], 'k-', linewidth=1)\n",
    "        y_pos -= 0.8\n",
    "        \n",
    "        # Controls\n",
    "        self.ax_status.text(5, y_pos, 'KEYBOARD CONTROLS', ha='center', fontsize=12, \n",
    "                           fontweight='bold', color='#2c3e50')\n",
    "        y_pos -= 0.8\n",
    "        \n",
    "        controls = [\n",
    "            ('SPACE', 'Start/Stop Calibration'),\n",
    "            ('Q', 'Quit Application'),\n",
    "            ('R', 'Reset & Recalibrate')\n",
    "        ]\n",
    "        \n",
    "        for key, action in controls:\n",
    "            self.ax_status.text(2, y_pos, f'[{key}]', ha='left', fontsize=10, \n",
    "                               fontweight='bold', color='#3498db')\n",
    "            self.ax_status.text(3.5, y_pos, action, ha='left', fontsize=10)\n",
    "            y_pos -= 0.7\n",
    "        \n",
    "        # Separator\n",
    "        y_pos -= 0.3\n",
    "        self.ax_status.plot([1, 9], [y_pos, y_pos], 'k-', linewidth=1)\n",
    "        y_pos -= 0.8\n",
    "        \n",
    "        # System info\n",
    "        self.ax_status.text(5, y_pos, f'FPS: {fps:.1f}', ha='center', fontsize=10, \n",
    "                           color='#7f8c8d')\n",
    "        y_pos -= 0.6\n",
    "        \n",
    "        # Current state\n",
    "        if self.is_calibrating:\n",
    "            self.ax_status.text(5, y_pos, '‚è≥ CALIBRATING...', ha='center', fontsize=11, \n",
    "                               fontweight='bold', color='#e67e22')\n",
    "        elif not self.calibrated:\n",
    "            self.ax_status.text(5, y_pos, 'Press SPACE to calibrate', ha='center', \n",
    "                               fontsize=10, color='#95a5a6', style='italic')\n",
    "    \n",
    "    def start_camera(self):\n",
    "        \"\"\"Start camera and run detection loop\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STARTING DETECTION\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\nüìπ Initializing camera...\")\n",
    "        \n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        if not self.cap.isOpened():\n",
    "            print(\"‚ùå Error: Could not open camera!\")\n",
    "            print(\"\\nTroubleshooting:\")\n",
    "            print(\"1. Check if another app is using the camera\")\n",
    "            print(\"2. Restart the kernel\")\n",
    "            print(\"3. Check camera permissions\")\n",
    "            return\n",
    "        \n",
    "        print(\"‚úÖ Camera initialized\")\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"INSTRUCTIONS:\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"1. Press SPACE to start calibration\")\n",
    "        print(\"2. Sit in proper upright posture during calibration\")\n",
    "        print(\"3. System will calibrate for ~1 second\")\n",
    "        print(\"4. Press Q to quit at any time\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        print(\"üìä Results window opened - check your taskbar!\\n\")\n",
    "        \n",
    "        self.is_running = True\n",
    "        frame_count = 0\n",
    "        calibration_frame_count = 0\n",
    "        last_time = time.time()\n",
    "        fps = 0\n",
    "        \n",
    "        try:\n",
    "            while self.is_running:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(\"‚ùå Could not read frame\")\n",
    "                    break\n",
    "                \n",
    "                # Calculate FPS\n",
    "                current_time = time.time()\n",
    "                fps = 1.0 / (current_time - last_time) if (current_time - last_time) > 0 else 0\n",
    "                last_time = current_time\n",
    "                \n",
    "                # Flip frame for mirror effect\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                \n",
    "                # Process with MediaPipe\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = self.pose.process(rgb_frame)\n",
    "                landmarks = self.detector.extract_landmarks(results.pose_landmarks)\n",
    "                \n",
    "                # Draw pose landmarks on frame\n",
    "                if results.pose_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                        mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                        mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)\n",
    "                    )\n",
    "                \n",
    "                posture = None\n",
    "                confidence = 0.0\n",
    "                \n",
    "                # Calibration logic\n",
    "                if self.is_calibrating:\n",
    "                    cv2.putText(frame, \"CALIBRATING: Hold upright posture...\", \n",
    "                               (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 122, 255), 3)\n",
    "                    \n",
    "                    progress = int((calibration_frame_count / 30) * 100)\n",
    "                    cv2.rectangle(frame, (10, 80), (10 + int(progress * 6), 110), \n",
    "                                 (0, 255, 0), -1)\n",
    "                    cv2.rectangle(frame, (10, 80), (610, 110), (255, 255, 255), 2)\n",
    "                    \n",
    "                    self.detector.calibrate_sample(landmarks)\n",
    "                    calibration_frame_count += 1\n",
    "                    \n",
    "                    if calibration_frame_count > 30:  # ~1 second\n",
    "                        self.is_calibrating = False\n",
    "                        self.calibrated = True\n",
    "                        self.detector.save_calibration()\n",
    "                        calibration_frame_count = 0\n",
    "                        print(\"‚úÖ Calibration complete!\")\n",
    "                \n",
    "                elif not self.calibrated:\n",
    "                    cv2.putText(frame, \"Press SPACE to calibrate\", \n",
    "                               (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 0), 3)\n",
    "                \n",
    "                # Posture detection (after calibration)\n",
    "                if self.calibrated and landmarks is not None:\n",
    "                    adj_landmarks = self.detector.delta_from_calibrated(landmarks)\n",
    "                    posture, confidence = self.detector.predict_posture(adj_landmarks)\n",
    "                    \n",
    "                    # Display posture on frame\n",
    "                    color = POSE_COLORS.get(posture, (255, 255, 255))\n",
    "                    cv2.putText(frame, f\"{posture.upper()}\", \n",
    "                               (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 4)\n",
    "                    cv2.putText(frame, f\"Confidence: {confidence:.0%}\", \n",
    "                               (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "                \n",
    "                # Display FPS\n",
    "                cv2.putText(frame, f\"FPS: {fps:.1f}\", \n",
    "                           (frame.shape[1] - 150, 30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                           0.7, (0, 255, 0), 2)\n",
    "                \n",
    "                # Update matplotlib display\n",
    "                self.ax_main.clear()\n",
    "                self.ax_main.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                self.ax_main.axis('off')\n",
    "                self.ax_main.set_title('Live Feed with Pose Detection', \n",
    "                                      fontsize=14, fontweight='bold')\n",
    "                \n",
    "                self.update_status_panel(posture, confidence, fps)\n",
    "                \n",
    "                plt.draw()\n",
    "                plt.pause(0.001)\n",
    "                \n",
    "                # Handle keyboard input\n",
    "                if plt.waitforbuttonpress(timeout=0.001):\n",
    "                    pass\n",
    "                \n",
    "                # Check for matplotlib window close\n",
    "                if not plt.fignum_exists(self.fig.number):\n",
    "                    print(\"\\nüõë Window closed\")\n",
    "                    break\n",
    "                \n",
    "                frame_count += 1\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüõë Stopped by user\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error during detection: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            self.cleanup()\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Release resources\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"CLEANING UP\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "            print(\"‚úì Camera released\")\n",
    "        \n",
    "        self.pose.close()\n",
    "        print(\"‚úì MediaPipe resources released\")\n",
    "        \n",
    "        plt.close('all')\n",
    "        print(\"‚úì Display windows closed\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SESSION COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "\n",
    "# Function to handle keyboard events\n",
    "def on_key_press(event, app):\n",
    "    \"\"\"Handle keyboard events\"\"\"\n",
    "    if event.key == ' ':  # Space bar\n",
    "        if not app.calibrated or not app.is_calibrating:\n",
    "            print(\"\\nüéØ Starting calibration - sit upright!\")\n",
    "            app.is_calibrating = True\n",
    "            app.calibrated = False\n",
    "    elif event.key == 'q':  # Q key\n",
    "        print(\"\\nüõë Quit requested\")\n",
    "        app.is_running = False\n",
    "    elif event.key == 'r':  # R key\n",
    "        print(\"\\nüîÑ Resetting calibration\")\n",
    "        app.calibrated = False\n",
    "        app.is_calibrating = False\n",
    "        app.detector.calibrated_upright = None\n",
    "\n",
    "\n",
    "# 1. Configuration - Set to 17 landmarks to reach 68 features\n",
    "# Indices 0-16 cover the face, shoulders, elbows, and wrists.\n",
    "LANDMARK_INDICES = list(range(17)) \n",
    "POSE_CLASSES = ['leaning_backward', 'leaning_forward', 'leaning_left', 'leaning_right', 'upright']\n",
    "\n",
    "def run_posture_detection(model_path, scaler_path, label_encoder_path):\n",
    "    # Initialize MediaPipe\n",
    "    mp_pose = mp.solutions.pose\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    pose_engine = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    \n",
    "    # Load Models\n",
    "    print(\"Loading AI models...\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    # Initialize Time Tracking\n",
    "    posture_timers = {pose: 0.0 for pose in POSE_CLASSES}\n",
    "    last_time = time.time()\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print(\"‚úì System Active. Use the 'Stop' button (square icon) in the toolbar to exit.\")\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "\n",
    "            # 2. Extract exactly 17 landmarks (68 features)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = pose_engine.process(frame_rgb)\n",
    "            \n",
    "            current_pose = \"Scanning...\"\n",
    "            landmark_canvas = np.zeros_like(frame)\n",
    "\n",
    "            if results.pose_landmarks:\n",
    "                features = []\n",
    "                # Extract 17 landmarks * 4 values (x, y, z, v) = 68 total\n",
    "                for idx in LANDMARK_INDICES:\n",
    "                    lm = results.pose_landmarks.landmark[idx]\n",
    "                    features.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "                \n",
    "                # 3. Prediction Logic\n",
    "                features_arr = np.array(features).reshape(1, -1)\n",
    "                \n",
    "                # Step A: Scale the 68 features\n",
    "                scaled_features = scaler.transform(features_arr)\n",
    "                \n",
    "                # Step B: Predict using the Model (now receiving the expected 68)\n",
    "                prediction = model.predict(scaled_features, verbose=0)\n",
    "                current_pose = POSE_CLASSES[np.argmax(prediction)]\n",
    "                \n",
    "                # 4. Time Tracking Update\n",
    "                now = time.time()\n",
    "                posture_timers[current_pose] += (now - last_time)\n",
    "                last_time = now\n",
    "                \n",
    "                # Draw skeleton on the landmark canvas\n",
    "                mp_drawing.draw_landmarks(landmark_canvas, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            # 5. Create Split View\n",
    "            combined = np.hstack((frame, landmark_canvas))\n",
    "            \n",
    "            # HUD Overlay\n",
    "            h, w, _ = frame.shape\n",
    "            cv2.putText(combined, f\"Pose: {current_pose.upper()}\", (20, 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            \n",
    "            y_offset = 40\n",
    "            for p_class, sec in posture_timers.items():\n",
    "                active = (p_class == current_pose)\n",
    "                color = (0, 255, 0) if active else (200, 200, 200)\n",
    "                cv2.putText(combined, f\"{p_class}: {sec:.1f}s\", (w + 20, y_offset), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2 if active else 1)\n",
    "                y_offset += 30\n",
    "\n",
    "            # 6. Jupyter-Safe Display\n",
    "            _, buffer = cv2.imencode('.png', combined)\n",
    "            display(Image.open(io.BytesIO(buffer)))\n",
    "            clear_output(wait=True)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        cap.release()\n",
    "        pose_engine.close()\n",
    "        print(\"\\nSession Summary:\")\n",
    "        for p, s in posture_timers.items():\n",
    "            print(f\"- {p}: {s:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d0c6759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\creat\\anaconda3\\envs\\pathml\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Session Summary:\n",
      "- leaning_backward: 45.40 seconds\n",
      "- leaning_forward: 70.96 seconds\n",
      "- leaning_left: 17.46 seconds\n",
      "- leaning_right: 107.67 seconds\n",
      "- upright: 1.02 seconds\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Run with default paths\n",
    "    #run_posture_detection()\n",
    "    \n",
    "    # Or specify custom paths:\n",
    "    run_posture_detection(\n",
    "         model_path='high_accuracy_posture_model_1758965690.h5',\n",
    "         scaler_path='high_accuracy_scaler_1758965690.pkl',\n",
    "         label_encoder_path='high_accuracy_encoder_1758965690.pkl'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc987e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
